# CL Crawler

看到小草上内容,吸引力十足,打算筛选出自己感兴趣的内容,躺倒硬盘
本次的目标(已实现):

* 墙内访问
> start_urls 爬取列表  
num_page 列表每项搜索页面数量
* 最新代理ip池   
> num_IP  ip池数量

* user-agent池
* 防网址重复爬取
* 防内容重复
* 自定义关心内容
> rules 包含关键词且图片数量大于30  
keep_if_exist_word 如果包含即爬取图片  
save_dir 本地存储目录


这里主要是爬取小草上个人比较喜欢的图片,基本上爬取1024主站的其他映像都是同种结构,根据墙内可访问资源定制.  
小草的网址是从百度搜的. 
搜索免费可用的代理用了不少时间,许多ip质量不佳,加上前端内容处理方式有些生疏,耗费了挺多时间
后面计划将信息存储到mongodb, 至于为什么选择mongo,mongo弱shema可以随时升级存储字段,同时具备索引能力

[transfer](https://www.zybuluo.com/liuhui0803/note/644770)
